{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09775f18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T03:33:45.889268Z",
     "iopub.status.busy": "2025-04-24T03:33:45.888879Z",
     "iopub.status.idle": "2025-04-24T03:33:54.430342Z",
     "shell.execute_reply": "2025-04-24T03:33:54.429247Z",
     "shell.execute_reply.started": "2025-04-24T03:33:45.889233Z"
    },
    "papermill": {
     "duration": 8.043041,
     "end_time": "2025-01-31T04:06:43.398675",
     "exception": false,
     "start_time": "2025-01-31T04:06:35.355634",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q pyterrier\n",
    "!pip install -q unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42e7174b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T03:33:54.432230Z",
     "iopub.status.busy": "2025-04-24T03:33:54.431881Z",
     "iopub.status.idle": "2025-04-24T03:33:57.248628Z",
     "shell.execute_reply": "2025-04-24T03:33:57.247722Z",
     "shell.execute_reply.started": "2025-04-24T03:33:54.432197Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 3.110382,
     "end_time": "2025-01-31T04:06:46.522167",
     "exception": false,
     "start_time": "2025-01-31T04:06:43.411785",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "def broadcast(src: torch.Tensor, other: torch.Tensor, dim: int):\n",
    "    if dim < 0:\n",
    "        dim = other.dim() + dim\n",
    "    if src.dim() == 1:\n",
    "        for _ in range(0, dim):\n",
    "            src = src.unsqueeze(0)\n",
    "    for _ in range(src.dim(), other.dim()):\n",
    "        src = src.unsqueeze(-1)\n",
    "    src = src.expand(other.size())\n",
    "    return src\n",
    "\n",
    "\n",
    "def scatter_sum(src: torch.Tensor,\n",
    "                index: torch.Tensor,\n",
    "                dim: int = -1,\n",
    "                out: Optional[torch.Tensor] = None,\n",
    "                dim_size: Optional[int] = None) -> torch.Tensor:\n",
    "    index = broadcast(index, src, dim)\n",
    "    if out is None:\n",
    "        size = list(src.size())\n",
    "        if dim_size is not None:\n",
    "            size[dim] = dim_size\n",
    "        elif index.numel() == 0:\n",
    "            size[dim] = 0\n",
    "        else:\n",
    "            size[dim] = int(index.max()) + 1\n",
    "        out = torch.zeros(size, dtype=src.dtype, device=src.device)\n",
    "        return out.scatter_add_(dim, index, src)\n",
    "    else:\n",
    "        return out.scatter_add_(dim, index, src)\n",
    "\n",
    "\n",
    "def scatter_add(src: torch.Tensor,\n",
    "                index: torch.Tensor,\n",
    "                dim: int = -1,\n",
    "                out: Optional[torch.Tensor] = None,\n",
    "                dim_size: Optional[int] = None) -> torch.Tensor:\n",
    "    return scatter_sum(src, index, dim, out, dim_size)\n",
    "\n",
    "\n",
    "def scatter_mul(src: torch.Tensor,\n",
    "                index: torch.Tensor,\n",
    "                dim: int = -1,\n",
    "                out: Optional[torch.Tensor] = None,\n",
    "                dim_size: Optional[int] = None) -> torch.Tensor:\n",
    "    return torch.ops.torch_scatter.scatter_mul(src, index, dim, out, dim_size)\n",
    "\n",
    "\n",
    "def scatter_mean(src: torch.Tensor,\n",
    "                 index: torch.Tensor,\n",
    "                 dim: int = -1,\n",
    "                 out: Optional[torch.Tensor] = None,\n",
    "                 dim_size: Optional[int] = None) -> torch.Tensor:\n",
    "    out = scatter_sum(src, index, dim, out, dim_size)\n",
    "    dim_size = out.size(dim)\n",
    "\n",
    "    index_dim = dim\n",
    "    if index_dim < 0:\n",
    "        index_dim = index_dim + src.dim()\n",
    "    if index.dim() <= index_dim:\n",
    "        index_dim = index.dim() - 1\n",
    "\n",
    "    ones = torch.ones(index.size(), dtype=src.dtype, device=src.device)\n",
    "    count = scatter_sum(ones, index, index_dim, None, dim_size)\n",
    "    count[count < 1] = 1\n",
    "    count = broadcast(count, out, dim)\n",
    "    if out.is_floating_point():\n",
    "        out.true_divide_(count)\n",
    "    else:\n",
    "        out.div_(count, rounding_mode='floor')\n",
    "    return out\n",
    "\n",
    "\n",
    "def scatter_min(\n",
    "        src: torch.Tensor,\n",
    "        index: torch.Tensor,\n",
    "        dim: int = -1,\n",
    "        out: Optional[torch.Tensor] = None,\n",
    "        dim_size: Optional[int] = None) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    return torch.ops.torch_scatter.scatter_min(src, index, dim, out, dim_size)\n",
    "\n",
    "\n",
    "def scatter_max(\n",
    "        src: torch.Tensor,\n",
    "        index: torch.Tensor,\n",
    "        dim: int = -1,\n",
    "        out: Optional[torch.Tensor] = None,\n",
    "        dim_size: Optional[int] = None) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    return torch.ops.torch_scatter.scatter_max(src, index, dim, out, dim_size)\n",
    "\n",
    "\n",
    "def scatter(src: torch.Tensor,\n",
    "            index: torch.Tensor,\n",
    "            dim: int = -1,\n",
    "            out: Optional[torch.Tensor] = None,\n",
    "            dim_size: Optional[int] = None,\n",
    "            reduce: str = \"sum\") -> torch.Tensor:\n",
    "    r\"\"\"\n",
    "    |\n",
    "\n",
    "    .. image:: https://raw.githubusercontent.com/rusty1s/pytorch_scatter/\n",
    "            master/docs/source/_figures/add.svg?sanitize=true\n",
    "        :align: center\n",
    "        :width: 400px\n",
    "\n",
    "    |\n",
    "\n",
    "    Reduces all values from the :attr:`src` tensor into :attr:`out` at the\n",
    "    indices specified in the :attr:`index` tensor along a given axis\n",
    "    :attr:`dim`.\n",
    "    For each value in :attr:`src`, its output index is specified by its index\n",
    "    in :attr:`src` for dimensions outside of :attr:`dim` and by the\n",
    "    corresponding value in :attr:`index` for dimension :attr:`dim`.\n",
    "    The applied reduction is defined via the :attr:`reduce` argument.\n",
    "\n",
    "    Formally, if :attr:`src` and :attr:`index` are :math:`n`-dimensional\n",
    "    tensors with size :math:`(x_0, ..., x_{i-1}, x_i, x_{i+1}, ..., x_{n-1})`\n",
    "    and :attr:`dim` = `i`, then :attr:`out` must be an :math:`n`-dimensional\n",
    "    tensor with size :math:`(x_0, ..., x_{i-1}, y, x_{i+1}, ..., x_{n-1})`.\n",
    "    Moreover, the values of :attr:`index` must be between :math:`0` and\n",
    "    :math:`y - 1`, although no specific ordering of indices is required.\n",
    "    The :attr:`index` tensor supports broadcasting in case its dimensions do\n",
    "    not match with :attr:`src`.\n",
    "\n",
    "    For one-dimensional tensors with :obj:`reduce=\"sum\"`, the operation\n",
    "    computes\n",
    "\n",
    "    .. math::\n",
    "        \\mathrm{out}_i = \\mathrm{out}_i + \\sum_j~\\mathrm{src}_j\n",
    "\n",
    "    where :math:`\\sum_j` is over :math:`j` such that\n",
    "    :math:`\\mathrm{index}_j = i`.\n",
    "\n",
    "    .. note::\n",
    "\n",
    "        This operation is implemented via atomic operations on the GPU and is\n",
    "        therefore **non-deterministic** since the order of parallel operations\n",
    "        to the same value is undetermined.\n",
    "        For floating-point variables, this results in a source of variance in\n",
    "        the result.\n",
    "\n",
    "    :param src: The source tensor.\n",
    "    :param index: The indices of elements to scatter.\n",
    "    :param dim: The axis along which to index. (default: :obj:`-1`)\n",
    "    :param out: The destination tensor.\n",
    "    :param dim_size: If :attr:`out` is not given, automatically create output\n",
    "        with size :attr:`dim_size` at dimension :attr:`dim`.\n",
    "        If :attr:`dim_size` is not given, a minimal sized output tensor\n",
    "        according to :obj:`index.max() + 1` is returned.\n",
    "    :param reduce: The reduce operation (:obj:`\"sum\"`, :obj:`\"mul\"`,\n",
    "        :obj:`\"mean\"`, :obj:`\"min\"` or :obj:`\"max\"`). (default: :obj:`\"sum\"`)\n",
    "\n",
    "    :rtype: :class:`Tensor`\n",
    "\n",
    "    .. code-block:: python\n",
    "\n",
    "        from torch_scatter import scatter\n",
    "\n",
    "        src = torch.randn(10, 6, 64)\n",
    "        index = torch.tensor([0, 1, 0, 1, 2, 1])\n",
    "\n",
    "        # Broadcasting in the first and last dim.\n",
    "        out = scatter(src, index, dim=1, reduce=\"sum\")\n",
    "\n",
    "        print(out.size())\n",
    "\n",
    "    .. code-block::\n",
    "\n",
    "        torch.Size([10, 3, 64])\n",
    "    \"\"\"\n",
    "    if reduce == 'sum' or reduce == 'add':\n",
    "        return scatter_sum(src, index, dim, out, dim_size)\n",
    "    if reduce == 'mul':\n",
    "        return scatter_mul(src, index, dim, out, dim_size)\n",
    "    elif reduce == 'mean':\n",
    "        return scatter_mean(src, index, dim, out, dim_size)\n",
    "    elif reduce == 'min':\n",
    "        return scatter_min(src, index, dim, out, dim_size)[0]\n",
    "    elif reduce == 'max':\n",
    "        return scatter_max(src, index, dim, out, dim_size)[0]\n",
    "    else:\n",
    "        raise ValueError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "211f6354",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T03:33:57.251101Z",
     "iopub.status.busy": "2025-04-24T03:33:57.250767Z",
     "iopub.status.idle": "2025-04-24T03:34:02.632718Z",
     "shell.execute_reply": "2025-04-24T03:34:02.632031Z",
     "shell.execute_reply.started": "2025-04-24T03:33:57.251081Z"
    },
    "papermill": {
     "duration": 7.769398,
     "end_time": "2025-01-31T04:06:54.304556",
     "exception": false,
     "start_time": "2025-01-31T04:06:46.535158",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, asdict, field\n",
    "import os\n",
    "from typing import Any, Dict, Optional\n",
    "import yaml\n",
    "import re\n",
    "import string\n",
    "import datetime\n",
    "import ast\n",
    "from os.path import join as join_path\n",
    "from collections import *\n",
    "import argparse\n",
    "import copy\n",
    "import glob\n",
    "from functools import partial\n",
    "from statistics import mean, median, StatisticsError\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import get_cosine_with_hard_restarts_schedule_with_warmup\n",
    "from torch import nn\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer, T5Config\n",
    "import collections\n",
    "from torch.optim import Optimizer\n",
    "import itertools\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np\n",
    "import json\n",
    "from typing import *\n",
    "import math\n",
    "import random\n",
    "import statistics\n",
    "from scipy.stats import norm\n",
    "from argparse import Namespace\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import string\n",
    "import pandas as pd\n",
    "import pyterrier as pt\n",
    "from unidecode import unidecode\n",
    "\n",
    "@dataclass\n",
    "class Model:\n",
    "    name: str = 'sentence-transformers/all-mpnet-base-v2'\n",
    "    pooling: str = 'default'  # 'mean', 'default'\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Train:\n",
    "    device: str = 'cuda' \n",
    "    dtype: str = 'float16'  # float32, float16, bfloat16\n",
    "    batch_size: int = 16\n",
    "    num_epochs: int = 20\n",
    "    accumulation_steps: int = 4\n",
    "    metrics_window_size: int = 128\n",
    "    warmup_steps: int = 400\n",
    "    evaluation_steps: int = -1  # If -1, after each epoch\n",
    "    label_smoothing: float = 0.  # [0, 1]\n",
    "    ema: bool = False  # Exponential moving average\n",
    "    freezing: bool = False  # Gradually makes early modules untrainable\n",
    "    output_path: Optional[str] = os.path.join('')  # If None, no model checkpointing every evaluation_steps\n",
    "    save_vectors: bool = False  # Whether to save vectors for evaluation\n",
    "    save_models: bool = True # Whether to save models\n",
    "    p_max_seq_length: int = 1024\n",
    "    fc_max_seq_length: int = 1024\n",
    "\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "@dataclass\n",
    "class Optimizer:\n",
    "    name: str = 'adamw' \n",
    "    lr: float = 5e-5\n",
    "    lr_transformer: float = 5e-5\n",
    "    lr_custom: float = 1e-4\n",
    "    weight_decay: float = 0.005 \n",
    "    clip_value: float = 1.0 \n",
    "    sam: bool = False\n",
    "    sam_step: float = 1. \n",
    "    sam_rho: float = 0.05 \n",
    "\n",
    "    \n",
    "@dataclass\n",
    "class Config:\n",
    "    model: Model = Model()\n",
    "    train: Train = Train()\n",
    "    optimizer: Optimizer = Optimizer()\n",
    "\n",
    "    seed: int = 3407\n",
    "\n",
    "    def __init__(self, path: Optional[str] = None):\n",
    "        self.timestamp = datetime.datetime.now().strftime('%d-%m-%Y-%H-%M-%S')\n",
    "        if path is not None: \n",
    "            with open(path, 'r') as f: self.init_class(yaml.load(f, Loader=yaml.SafeLoader))\n",
    "        \n",
    "    def to_dict(self):\n",
    "        return asdict(self)\n",
    "    \n",
    "    def init_class(self, d):\n",
    "        for name in dir(self):\n",
    "            if name.startswith('_') or name.endswith('_') or name not in d:\n",
    "                continue\n",
    "            attr = getattr(self, name)\n",
    "            if isinstance(d[name], dict):\n",
    "                for k, v in d[name].items():\n",
    "                    setattr(attr, k, v)\n",
    "            else: \n",
    "                setattr(self, name, d[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4970e7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T03:34:02.634375Z",
     "iopub.status.busy": "2025-04-24T03:34:02.633851Z",
     "iopub.status.idle": "2025-04-24T03:34:02.649340Z",
     "shell.execute_reply": "2025-04-24T03:34:02.648369Z",
     "shell.execute_reply.started": "2025-04-24T03:34:02.634341Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.02833,
     "end_time": "2025-01-31T04:06:54.345832",
     "exception": false,
     "start_time": "2025-01-31T04:06:54.317502",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Library of various cleaning-related functions, regular expressions and variables.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "simple_latin = string.ascii_lowercase + string.ascii_uppercase\n",
    "dirty_chars = string.digits + string.punctuation\n",
    "\n",
    "\n",
    "def is_clean_text(text: str) -> bool:\n",
    "    \"\"\"\n",
    "    Simple text cleaning method.\n",
    "    \"\"\"\n",
    "    dirty = (\n",
    "        len(text) < 25                                               # Short text\n",
    "        or\n",
    "        0.5 < sum(char in dirty_chars for char in text) / len(text)  # More than 50% dirty chars                                            \n",
    "    )\n",
    "    return not dirty\n",
    "\n",
    "\n",
    "# Source: https://gist.github.com/dperini/729294\n",
    "url_regex = re.compile(\n",
    "    r'(?:^|(?<![\\w\\/\\.]))'\n",
    "    r'(?:(?:https?:\\/\\/|ftp:\\/\\/|www\\d{0,3}\\.))'\n",
    "    r'(?:\\S+(?::\\S*)?@)?' r'(?:'\n",
    "    r'(?!(?:10|127)(?:\\.\\d{1,3}){3})'\n",
    "    r'(?!(?:169\\.254|192\\.168)(?:\\.\\d{1,3}){2})'\n",
    "    r'(?!172\\.(?:1[6-9]|2\\d|3[0-1])(?:\\.\\d{1,3}){2})'\n",
    "    r'(?:[1-9]\\d?|1\\d\\d|2[01]\\d|22[0-3])'\n",
    "    r'(?:\\.(?:1?\\d{1,2}|2[0-4]\\d|25[0-5])){2}'\n",
    "    r'(?:\\.(?:[1-9]\\d?|1\\d\\d|2[0-4]\\d|25[0-4]))'\n",
    "    r'|'\n",
    "    r'(?:(?:[a-z\\\\u00a1-\\\\uffff0-9]-?)*[a-z\\\\u00a1-\\\\uffff0-9]+)'\n",
    "    r'(?:\\.(?:[a-z\\\\u00a1-\\\\uffff0-9]-?)*[a-z\\\\u00a1-\\\\uffff0-9]+)*'\n",
    "    r'(?:\\.(?:[a-z\\\\u00a1-\\\\uffff]{2,}))' r'|' r'(?:(localhost))' r')'\n",
    "    r'(?::\\d{2,5})?'\n",
    "    r'(?:\\/[^\\)\\]\\}\\s]*)?',\n",
    "    flags=re.IGNORECASE,\n",
    ")\n",
    "\n",
    "\n",
    "def remove_urls(text: str) -> str:\n",
    "    return url_regex.sub('', text)\n",
    "\n",
    "\n",
    "# Source: https://gist.github.com/Nikitha2309/15337f4f593c4a21fb0965804755c41d\n",
    "emoji_regex = re.compile('['\n",
    "        u'\\U0001F600-\\U0001F64F'  # emoticons\n",
    "        u'\\U0001F300-\\U0001F5FF'  # symbols & pictographs\n",
    "        u'\\U0001F680-\\U0001F6FF'  # transport & map symbols\n",
    "        u'\\U0001F1E0-\\U0001F1FF'  # flags (iOS)\n",
    "        u'\\U00002500-\\U00002BEF'  # chinese char\n",
    "        u'\\U00002702-\\U000027B0'\n",
    "        u'\\U00002702-\\U000027B0'\n",
    "        u'\\U000024C2-\\U0001F251'\n",
    "        u'\\U0001f926-\\U0001f937'\n",
    "        u'\\U00010000-\\U0010ffff'\n",
    "        u'\\u2640-\\u2642'\n",
    "        u'\\u2600-\\u2B55'\n",
    "        u'\\u200d'\n",
    "        u'\\u23cf'\n",
    "        u'\\u23e9'\n",
    "        u'\\u231a'\n",
    "        u'\\ufe0f'  # dingbats\n",
    "        u'\\u3030'\n",
    "    ']+')\n",
    "\n",
    "\n",
    "def remove_emojis(text: str) -> str:\n",
    "    return emoji_regex.sub('', text)\n",
    "\n",
    "\n",
    "sentence_stop_regex = re.compile('['\n",
    "    u'\\u002e' # full stop\n",
    "    u'\\u2026' # ellipsis\n",
    "    u'\\u061F' # arabic question mark\n",
    "    u'\\u06D4' # arabic full stop\n",
    "    u'\\u2022' # bullet point\n",
    "    u'\\u3002' # chinese period\n",
    "    u'\\u25CB' # white circle\n",
    "    '\\|'      # pipe\n",
    "']+')\n",
    "\n",
    "\n",
    "def replace_stops(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Replaces some characters that are being used to end sentences. Used for sentence segmentation with sliding windows.\n",
    "    \"\"\"\n",
    "    return sentence_stop_regex.sub('.', text)\n",
    "\n",
    "\n",
    "whitespace_regex = re.compile(r'\\s+')\n",
    "\n",
    "\n",
    "def replace_whitespaces(text: str) -> str:\n",
    "    return whitespace_regex.sub(' ', text)\n",
    "\n",
    "\n",
    "def clean_ocr(ocr: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove all lines that are shorter than 6 and have more than 50% `dirty_chars`.\n",
    "    \"\"\"\n",
    "    return '\\n'.join(\n",
    "        line\n",
    "        for line in ocr.split('\\n')\n",
    "        if len(line) > 5 and sum(char in dirty_chars for char in line) / len(line) < 0.5\n",
    "    )\n",
    "\n",
    "\n",
    "def clean_twitter_picture_links(text):\n",
    "    \"\"\"\n",
    "    Replaces links to picture in twitter post only with 'pic'. \n",
    "    \"\"\"\n",
    "    return re.sub(r'pic.twitter.com/\\S+', 'pic', text)\n",
    "\n",
    "\n",
    "def clean_twitter_links(text):\n",
    "    \"\"\"\n",
    "    Replaces twitter links with 't.co'.\n",
    "    \"\"\"\n",
    "    return re.sub(r'\\S+//t.co/\\S+', 't.co', text)\n",
    "\n",
    "\n",
    "def remove_elongation(text):\n",
    "    \"\"\"\n",
    "    Replaces any occurrence of a string of consecutive identical non-space \n",
    "    characters (at least three in a row) with just one instance of that character.\n",
    "    \"\"\"\n",
    "    text = re.sub(r'(\\S+)\\1{2,}', r'\\1', text)\n",
    "    return text\n",
    "\n",
    "def safe_literal_eval(value):\n",
    "    try:\n",
    "        return ast.literal_eval(str(value))\n",
    "    except (ValueError, SyntaxError):\n",
    "        return value  # Or `None`, depending on how you want to handle it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22aa3c9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T03:34:02.650335Z",
     "iopub.status.busy": "2025-04-24T03:34:02.650083Z",
     "iopub.status.idle": "2025-04-24T03:34:02.661761Z",
     "shell.execute_reply": "2025-04-24T03:34:02.660973Z",
     "shell.execute_reply.started": "2025-04-24T03:34:02.650315Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.020298,
     "end_time": "2025-01-31T04:06:54.378466",
     "exception": false,
     "start_time": "2025-01-31T04:06:54.358168",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Library of custom types used for datasets. Some basic functions over these types are also included.\n",
    "\"\"\"\n",
    "\n",
    "Id2FactCheck = Dict[int, str]\n",
    "Id2Post = Dict[int, str]\n",
    "FactCheckPostMapping = List[Tuple[int, int]]\n",
    "\n",
    "Language = str  # ISO 639-3 language code\n",
    "LanguageDistribution = Dict[Language, float]  # Confidence for language identification. Should sum to [0, 1].\n",
    "\n",
    "OriginalText = str\n",
    "EnglishTranslation = str\n",
    "TranslatedText = Tuple[OriginalText, EnglishTranslation, LanguageDistribution]\n",
    "\n",
    "Instance = Tuple[Optional[datetime.datetime], str]  # When and where was a fact-check or post published\n",
    "\n",
    "\n",
    "def is_in_distribution(language: Language, distribution: LanguageDistribution, threshold: float = 0.2) -> bool:\n",
    "    \"\"\"\n",
    "    Check whether `language` is in a `distribution` with more than `treshold` x 100%\n",
    "    \"\"\"\n",
    "    return next(\n",
    "        (\n",
    "            percentage >= threshold\n",
    "            for distribution_language, percentage in distribution\n",
    "            if distribution_language == language\n",
    "        ),\n",
    "        False\n",
    "    )\n",
    "\n",
    "\n",
    "def combine_distributions(texts: Iterable[TranslatedText]) -> LanguageDistribution:\n",
    "    \"\"\"\n",
    "    Combine `LanguageDistribution`s from multiple `TranslatedText`s taking the length of the text into consideration.\n",
    "    \"\"\"\n",
    "    total_length = sum(len(text[0]) for text in texts)\n",
    "    distribution = defaultdict(lambda: 0)\n",
    "    for original_text, _, text_distribution in texts:\n",
    "        for language, percentage in text_distribution:\n",
    "            distribution[language] += percentage * len(original_text) / total_length\n",
    "    return list(distribution.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9af0800a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T03:34:02.662936Z",
     "iopub.status.busy": "2025-04-24T03:34:02.662641Z",
     "iopub.status.idle": "2025-04-24T03:34:02.679153Z",
     "shell.execute_reply": "2025-04-24T03:34:02.678457Z",
     "shell.execute_reply.started": "2025-04-24T03:34:02.662908Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.024756,
     "end_time": "2025-01-31T04:06:54.417210",
     "exception": false,
     "start_time": "2025-01-31T04:06:54.392454",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    \"\"\"Dataset\n",
    "    \n",
    "    Abstract class for datasets. Subclasses should implement `load` function that load `id_to_fact_check`, `id_to_post`,\n",
    "    and `fact_check_post_mapping` object attributes. The class also implemenets basic cleaning methods that might be\n",
    "    reused.\n",
    "    \n",
    "    Attributes:\n",
    "        clean_ocr: bool = True  Should cleaning of OCRs be performed\n",
    "        remove_emojis: bool = False  Should emojis be removed from the texts?\n",
    "        remove_urls: bool = True  Should URLs be removed from the texts?\n",
    "        replace_whitespaces: bool = True  Should whitespaces be replaced by a single space whitespace?\n",
    "        clean_twitter: bool = True  \n",
    "        remove_elongation: bool = False  Should occurrence of a string of consecutive identical non-space \n",
    "    characters (at least three in a row) with just one instance of that character?\n",
    "\n",
    "        After `load` is called, following attributes are accesible:\n",
    "                fact_check_post_mapping: list[tuple[int, int]]  List of Factcheck-Post id pairs.\n",
    "                id_to_fact_check: dict[int, str]  Factcheck id -> Factcheck text\n",
    "                id_to_post: dict[int, str]  Post id -> Post text\n",
    "                \n",
    "    Methods:\n",
    "        clean_text: Performs text cleaning based on initialization attributes.\n",
    "        maybe_clean_ocr: Perform OCR-specific text cleaning, if `self.clean_ocr`\n",
    "        load: Abstract method. To be implemented by the subclasses.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # The default values here are based on our preliminary experiments. Might not be the best for all cases.\n",
    "    def __init__(\n",
    "        self,\n",
    "        clean_ocr: bool = True,\n",
    "        dataset: str = None,  # Here to read and discard the `dataset` field from the argparser\n",
    "        remove_emojis: bool = True,\n",
    "        remove_urls: bool = True,\n",
    "        replace_whitespaces: bool = True,\n",
    "        clean_twitter: bool = True,\n",
    "        remove_elongation: bool = False\n",
    "    ):\n",
    "        self.clean_ocr = clean_ocr\n",
    "        self.remove_emojis = remove_emojis\n",
    "        self.remove_urls = remove_urls\n",
    "        self.replace_whitespaces = replace_whitespaces\n",
    "        self.clean_twitter = clean_twitter\n",
    "        self.remove_elongation = remove_elongation\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.fact_check_post_mapping)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        p_id, fc_id = self.fact_check_post_mapping[idx]\n",
    "        return self.id_to_fact_check[fc_id], self.id_to_post[p_id]\n",
    "\n",
    "        \n",
    "    def clean_text(self, text):\n",
    "        \n",
    "        if self.remove_urls:\n",
    "            text = remove_urls(text)\n",
    "\n",
    "        if self.remove_emojis:\n",
    "            text = remove_emojis(text)\n",
    "\n",
    "        if self.replace_whitespaces:\n",
    "            text = replace_whitespaces(text)\n",
    "        \n",
    "        if self.clean_twitter:\n",
    "            text = clean_twitter_picture_links(text)\n",
    "            text = clean_twitter_links(text)\n",
    "        \n",
    "        if self.remove_elongation:\n",
    "            text = remove_elongation(text)\n",
    "\n",
    "        return text.strip()        \n",
    "        \n",
    "        \n",
    "    def maybe_clean_ocr(self, ocr):\n",
    "        if self.clean_ocr:\n",
    "            return clean_ocr(ocr)\n",
    "        return ocr\n",
    "        \n",
    "    \n",
    "    def __getattr__(self, name):\n",
    "        if name in {'id_to_fact_check', 'id_to_post', 'fact_check_post_mapping'}:\n",
    "            raise AttributeError(f\"You have to `load` the dataset first before using '{name}'\")\n",
    "        raise AttributeError(f\"'{self.__class__.__name__}' object has no attribute '{name}'\")\n",
    "\n",
    "        \n",
    "    def load(self):\n",
    "        raise NotImplementedError\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9efed456",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T03:34:02.680453Z",
     "iopub.status.busy": "2025-04-24T03:34:02.680243Z",
     "iopub.status.idle": "2025-04-24T03:34:02.696317Z",
     "shell.execute_reply": "2025-04-24T03:34:02.695681Z",
     "shell.execute_reply.started": "2025-04-24T03:34:02.680435Z"
    },
    "papermill": {
     "duration": 0.027396,
     "end_time": "2025-01-31T04:06:54.459285",
     "exception": false,
     "start_time": "2025-01-31T04:06:54.431889",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class OurDataset(Dataset):\n",
    "    \"\"\"Our dataset\n",
    "    \n",
    "    Class for our dataset that can load different variants. It requires data from `drive/datasets/ours`.\n",
    "\n",
    "    Initialization Attributes:\n",
    "        crosslingual: bool  If `True`, only crosslingual pairs (fact-check and post in different languages) are loaded.\n",
    "        fact_check_fields: Iterable[str]  List of fields used to generate the final `str` representation for fact-checks. Supports `claim` and `title`.\n",
    "        fact_check_language: Optional[Language]  If a `Language` is specified, only fact-checks with that language are selected.\n",
    "        language: Optional[Language]  If a `Language` is specified, only fact-checks and posts with that language are selected.\n",
    "        post_language: Optional[Language]  If a `Language` is specified, only posts with that language are selected.\n",
    "        split: `train`, `test` or `dev`. `None` means all the samples.\n",
    "        version: 'original' or 'english'. Language version of the dataset.\n",
    "        \n",
    "        Also check `Dataset` attributes.\n",
    "        \n",
    "        After `load` is called, following attributes are accesible:\n",
    "            fact_check_post_mapping: list[tuple[int, int]]  List of Factcheck-Post id pairs.\n",
    "            id_to_fact_check: dict[int, str]  Factcheck id -> Factcheck text\n",
    "            id_to_post: dict[int, str]  Post id -> Post text\n",
    "        \n",
    "\n",
    "    Methods:\n",
    "        load: Loads the data from the csv files. Populates `id_to_fact_check`, `id_to_post` and `fact_check_post_mapping` attributes.\n",
    "    \"\"\"\n",
    "        \n",
    "    our_dataset_path = join_path('/semeval-data')\n",
    "    csvs_loaded = False\n",
    "\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        crosslingual: bool = False,\n",
    "        fact_check_fields: Iterable[str] = ('claim', 'title'),\n",
    "        fact_check_language: Optional[Language] = None,\n",
    "        language: Optional[Language] = None,\n",
    "        post_language: Optional[Language] = None,\n",
    "        split: Optional[str] = None,\n",
    "        # version: str = 'original',\n",
    "        fold: int = 0,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        assert all(field in ('claim', 'title') for field in fact_check_fields)\n",
    "        assert split in ('test', 'train')\n",
    "        \n",
    "        # self.crosslingual = crosslingual\n",
    "        self.split = split\n",
    "        self.fold = fold\n",
    "        self.language = language\n",
    "        \n",
    "    @classmethod\n",
    "    def maybe_load_csvs(cls):\n",
    "        \"\"\"\n",
    "        Load the csvs and store them as class variables. When individual objects are initialized, they can reuse the same\n",
    "        pre-loaded dataframes without costly text parsing.\n",
    "        \n",
    "        `OurDataset.csvs_loaded` is a flag indicating whether the csvs are already loaded.\n",
    "        \"\"\"\n",
    "        \n",
    "        if cls.csvs_loaded:\n",
    "            return\n",
    "        \n",
    "        posts_path = join_path(cls.our_dataset_path, 'test_posts_text.csv')\n",
    "        fact_checks_path = join_path(cls.our_dataset_path, 'test_fact_checks_text.csv')\n",
    "        \n",
    "        for path in [posts_path, fact_checks_path]:\n",
    "            assert os.path.isfile(path)\n",
    "        \n",
    "        print('Loading fact-checks.')\n",
    "        cls.df_fact_checks = pd.read_csv(fact_checks_path).fillna('').set_index('fact_check_id')\n",
    "        print(f'{len(cls.df_fact_checks)} loaded.')\n",
    "\n",
    "            \n",
    "        print('Loading posts.')\n",
    "        cls.df_posts = pd.read_csv(posts_path).fillna('').set_index('post_id')\n",
    "        print(f'{len(cls.df_posts)} loaded.')\n",
    "\n",
    "        cls.csvs_loaded = True\n",
    "        \n",
    "\n",
    "    def load(self):\n",
    "        \n",
    "        self.maybe_load_csvs()\n",
    "        \n",
    "        df_posts = self.df_posts.copy()\n",
    "        df_fact_checks = self.df_fact_checks.copy()\n",
    "\n",
    "        print(df_fact_checks['post_lang'].value_counts())\n",
    "        \n",
    "        if self.language != 'cross':\n",
    "\n",
    "            df = pd.read_json('/semeval-data/SemEval_Task7_Test_Phase/tasks.json').reset_index()\n",
    "            lang_fact_checks = df[df['index']==self.language]['monolingual'].values[0]['fact_checks']\n",
    "            print('task lang fact checks', len(lang_fact_checks))\n",
    "            lang_post_dev = df[df['index']==self.language]['monolingual'].values[0]['posts_test']\n",
    "            print('task lang post dev', len(lang_post_dev))\n",
    "\n",
    "            df_fact_checks = df_fact_checks[df_fact_checks.index.isin(lang_fact_checks)]\n",
    "            df_posts = df_posts[df_posts.index.isin(lang_post_dev)]\n",
    "    \n",
    "            print(f'Filtering by split: {len(df_posts)} posts remaining and sampled {len(df_fact_checks)} fact checks')\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            df = pd.read_json('/semeval-data/SemEval_Task7_Test_Phase/tasks.json').reset_index()\n",
    "            lang_fact_checks = df[df['index']=='fact_checks']['crosslingual'].dropna().values[0]\n",
    "            print('task lang fact checks', len(lang_fact_checks))\n",
    "            lang_post_dev = df[df['index']=='posts_test']['crosslingual'].dropna().values[0]\n",
    "            print('task lang post dev', len(lang_post_dev))\n",
    "\n",
    "            df_fact_checks = df_fact_checks[df_fact_checks.index.isin(lang_fact_checks)]\n",
    "            df_posts = df_posts[df_posts.index.isin(lang_post_dev)]\n",
    "    \n",
    "            print(f'Filtering by split: {len(df_posts)} posts remaining and sampled {len(df_fact_checks)} fact checks')\n",
    "\n",
    "        print(f'Filtering fact-checks by language: {len(df_fact_checks)} posts remaining.')\n",
    "        print(f'Filtering posts by language: {len(df_posts)} posts remaining.')\n",
    "        print(f'Filtering posts.')\n",
    "        print(f'Posts remaining: {len(df_posts)}')\n",
    "            \n",
    "\n",
    "        self.id_to_post = dict()\n",
    "        for post_id, post_text in zip(df_posts.index, df_posts['clean_text']):\n",
    "            self.id_to_post[post_id] = self.clean_text(post_text)\n",
    "\n",
    "        self.id_to_fact_check = dict()\n",
    "        for fact_check_id, fact_text in zip(df_fact_checks.index, df_fact_checks['clean_text']):\n",
    "            self.id_to_fact_check[fact_check_id] = self.clean_text(fact_text)\n",
    "            \n",
    "        return self\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4033b07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T03:34:02.698872Z",
     "iopub.status.busy": "2025-04-24T03:34:02.698619Z",
     "iopub.status.idle": "2025-04-24T03:34:02.796687Z",
     "shell.execute_reply": "2025-04-24T03:34:02.795734Z",
     "shell.execute_reply.started": "2025-04-24T03:34:02.698853Z"
    },
    "papermill": {
     "duration": 0.115189,
     "end_time": "2025-01-31T04:06:54.589613",
     "exception": false,
     "start_time": "2025-01-31T04:06:54.474424",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task lang fact checks 272447\n",
      "task lang post dev 4000\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json('semeval-data/SemEval_Task7_Test_Phase/tasks.json').reset_index()\n",
    "lang_fact_checks = df[df['index']=='fact_checks']['crosslingual'].dropna().values[0]\n",
    "print('task lang fact checks', len(lang_fact_checks))\n",
    "lang_post_dev = df[df['index']=='posts_test']['crosslingual'].dropna().values[0]\n",
    "print('task lang post dev', len(lang_post_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15ca349a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T03:34:02.797988Z",
     "iopub.status.busy": "2025-04-24T03:34:02.797726Z",
     "iopub.status.idle": "2025-04-24T03:34:02.803849Z",
     "shell.execute_reply": "2025-04-24T03:34:02.802937Z",
     "shell.execute_reply.started": "2025-04-24T03:34:02.797956Z"
    },
    "papermill": {
     "duration": 0.023287,
     "end_time": "2025-01-31T04:06:54.626630",
     "exception": false,
     "start_time": "2025-01-31T04:06:54.603343",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_result_generator(gen: Generator, default_rank: int = None, csv_path: str = None):\n",
    "    \"\"\"\n",
    "    Take the results generated from `gen` and process them. By default, only calculate metrics, but dumping the results into a csv file is also supported\n",
    "    via `csv_path` attribute. For `default_rank` see `predicted_ranks` function.\n",
    "    \"\"\"\n",
    "    ranks = list()\n",
    "    rows = list()\n",
    "    for predicted_ids, probab_ids, post_id in gen:\n",
    "        if csv_path:\n",
    "            rows.append((post_id, probab_ids[:50], predicted_ids[:50]))\n",
    "    if csv_path:\n",
    "        pd.DataFrame(rows, columns=['post_id', 'predicted_fact_check_probs',\n",
    "                                    'predicted_fact_check_ids']).to_csv(csv_path, index=False)\n",
    "    print('done')\n",
    "def result_generator(func):\n",
    "    \"\"\"\n",
    "    This is a decorator function that should be used on result generators. The generators return by default: `predicted_fact_check_ids` and `post_id`.\n",
    "    Here, the results are enriched with the `desired_fact_check_ids` as indicated by `dataset.fact_check_post_mapping`\n",
    "    \"\"\"\n",
    "    def wrapper(dataset, *args, **kwargs):\n",
    "        for predicted_fact_check_ids, probab_ids, post_id in func(dataset, *args, **kwargs):\n",
    "            yield predicted_fact_check_ids, probab_ids, post_id\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85bcad17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T03:34:02.805005Z",
     "iopub.status.busy": "2025-04-24T03:34:02.804711Z",
     "iopub.status.idle": "2025-04-24T03:34:02.819057Z",
     "shell.execute_reply": "2025-04-24T03:34:02.818318Z",
     "shell.execute_reply.started": "2025-04-24T03:34:02.804970Z"
    },
    "papermill": {
     "duration": 0.02274,
     "end_time": "2025-01-31T04:06:54.661567",
     "exception": false,
     "start_time": "2025-01-31T04:06:54.638827",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Vectorizer:\n",
    "    \"\"\"\n",
    "    An abstract class for vectorizers. Vectorizers calculate vectors for texts and handle thir caching so that we do not have to calculate\n",
    "    the vector for the same text more than once.\n",
    "    \n",
    "    Currently supported:\n",
    "            `SentenceTransformerVectorizer` - Used for models using `sentence_transformers` library.\n",
    "            `LaserVectorizer` - TBA\n",
    "            `PytorchVectorizer` - Used for pytorch models (nn.Module).\n",
    "            \n",
    "    The main call for `Vectorizer` is `vectorize`. This will calculate the appropriate vectors and store them in the `dict` attribute. The class also\n",
    "    supports `save` and `load`. `dir_path` is used as path to a folder where there is a `vocab.json` stored with the collection of texts and `vectors.py`\n",
    "    with a torch tensor of vectors for the texts.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dir_path: str):\n",
    "        self.dict = {}\n",
    "        \n",
    "        self.dir_path = dir_path\n",
    "        if dir_path:\n",
    "            self.vectors_path = os.path.join(dir_path, 'vectors.pt')\n",
    "            self.vocab_path = os.path.join(dir_path, 'vocab.json')\n",
    "        \n",
    "            try:\n",
    "                self.load()\n",
    "                print(f'Vector database with {len(self.dict)} records loaded')\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "                print(f'No previous database found')\n",
    "\n",
    "        \n",
    "    def vectorize(self, texts: List[str], save_if_missing: bool = False, normalize: bool = False) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        The main API point for the users. Try to find the vectors in the existing database. For the missing texts, the vectors will be calculated\n",
    "        and saved in the `self.dict`. \n",
    "        \n",
    "        Attributes:\n",
    "            save_if_missing: bool  Should the vectors in `dict` be saved after new vectors are calculated? This makes sense for models that will\n",
    "                be used more than once.\n",
    "            normalize: bool  Should the vectors be normalized. Useful for cosine similarity calculations.\n",
    "        \"\"\"\n",
    "        \n",
    "        missing_texts = list(set(texts) - set(self.dict.keys()))\n",
    "        \n",
    "        if missing_texts:\n",
    "            \n",
    "            print(f'Calculating {len(missing_texts)} vectors.')\n",
    "            missing_vectors = self._calculate_vectors(missing_texts)\n",
    "            for text, vector in zip(missing_texts, missing_vectors):\n",
    "                self.dict[text] = vector\n",
    "            \n",
    "            if save_if_missing:\n",
    "                self.save()\n",
    "            \n",
    "        vectors = torch.vstack([\n",
    "            self.dict[text]\n",
    "            for text in texts\n",
    "        ])\n",
    "        \n",
    "        if normalize:\n",
    "            vectors = torch.nn.functional.normalize(vectors, p=2, dim=1)\n",
    "            \n",
    "        return vectors\n",
    "\n",
    "    \n",
    "    def _calculate_vectors(self, txts: List[str]) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Abstract method to be implemented by subclasses.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "            \n",
    "    def load(self):\n",
    "        \"\"\"\n",
    "        Load vocab and vectors from appropriate files\n",
    "        \"\"\"\n",
    "        with open(self.vocab_path, 'r', encoding='utf8') as f:\n",
    "            vocab = json.load(f)\n",
    "        \n",
    "        vectors = torch.load(self.vectors_path)\n",
    "        \n",
    "        assert len(vocab) == len(vectors)\n",
    "        \n",
    "        self.dict = {\n",
    "            text: vector\n",
    "            for text, vector in zip(vocab, vectors)\n",
    "        }\n",
    "        \n",
    "        \n",
    "    def save(self):\n",
    "        \"\"\"\n",
    "        Save vocab and vectors to appropriate files\n",
    "        \"\"\"\n",
    "        os.makedirs(self.dir_path, exist_ok=True)\n",
    "            \n",
    "        vocab = list(self.dict.keys())        \n",
    "        with open(self.vocab_path, 'w', encoding='utf8') as f:\n",
    "            json.dump(vocab, f)\n",
    "            \n",
    "        vectors = torch.vstack(list(self.dict.values()))\n",
    "        torch.save(vectors, self.vectors_path)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cd2d0cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T03:34:02.819947Z",
     "iopub.status.busy": "2025-04-24T03:34:02.819719Z",
     "iopub.status.idle": "2025-04-24T03:34:02.835398Z",
     "shell.execute_reply": "2025-04-24T03:34:02.834657Z",
     "shell.execute_reply.started": "2025-04-24T03:34:02.819928Z"
    },
    "papermill": {
     "duration": 0.026655,
     "end_time": "2025-01-31T04:06:54.700699",
     "exception": false,
     "start_time": "2025-01-31T04:06:54.674044",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def slice_text(text, window_type, window_size, window_stride=None) -> List[str]:\n",
    "    \"\"\"\n",
    "    Split a `text` into parts using a sliding window. The windows slides either across characters or sentences, based on the value of `window_tyoe`.\n",
    "\n",
    "    Attributes:\n",
    "        text: str  Text that is to be splitted into windows.\n",
    "        window_type: str  Either `sentence` or `character`. The basic unit of the windows.\n",
    "        window_size: int  How many units are in a window.\n",
    "        window_stride: int  How many units are skipped each time the window moves.\n",
    "    \"\"\"\n",
    "\n",
    "    text = replace_whitespaces(text)\n",
    "\n",
    "    if window_stride is None:\n",
    "        window_stride = window_size\n",
    "\n",
    "    if window_size < window_stride:\n",
    "        print(f'Window size ({window_size}) is smaller than stride length ({window_stride}). This will result in missing chunks of text.')\n",
    "\n",
    "\n",
    "    if window_type == 'sentence':\n",
    "        text = replace_stops(text)\n",
    "        sentences = sent_tokenize(text)\n",
    "        return [\n",
    "            ' '.join(sentences[i:i+window_size])\n",
    "            for i in range(0, len(sentences), window_stride)\n",
    "        ]\n",
    "\n",
    "    elif window_type == 'character':\n",
    "        return [\n",
    "            text[i:i+window_size]\n",
    "            for i in range(0, len(text), window_stride)\n",
    "        ]\n",
    "\n",
    "\n",
    "def gen_sliding_window_delimiters(post_lengths: List[int], max_size: int) -> Generator[Tuple[int, int], None, None]:\n",
    "    \"\"\"\n",
    "    Calculate where to split the sequence of `post_lenghts` so that the individual batches do not exceed `max_size`\n",
    "    \"\"\"\n",
    "    range_length = start = cur_sum = 0\n",
    "\n",
    "    for post_length in post_lengths:\n",
    "        if (range_length + post_length) > max_size: # exceeds memory\n",
    "            yield (start, start + range_length)\n",
    "            start = cur_sum\n",
    "            range_length = post_length\n",
    "        else: # memory still avail in current split\n",
    "            range_length += post_length\n",
    "        cur_sum += post_length\n",
    "\n",
    "    if range_length > 0:\n",
    "        yield (start, start + range_length)\n",
    "\n",
    "\n",
    "@result_generator\n",
    "def embedding_results(\n",
    "    dataset: Dataset,\n",
    "    vectorizer_fact_check: Vectorizer,\n",
    "    vectorizer_post: Vectorizer,\n",
    "    sliding_window: bool = False,\n",
    "    sliding_window_pooling: str = 'max',\n",
    "    sliding_window_size: int = None,\n",
    "    sliding_window_stride: int = None,\n",
    "    sliding_window_type: str = None,\n",
    "    post_split_size: int = 256,\n",
    "    dtype: torch.dtype = torch.float16,\n",
    "    device: str = 'cpu',\n",
    "    save_if_missing: bool = False\n",
    "\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate results using cosine similarity based on embeddings generated via vectorizers.\n",
    "\n",
    "    Attributes:\n",
    "        dataset: Dataset\n",
    "        vectorizer_fact_check: Vectorizer  Vectorizer used to process fact-checks\n",
    "        vectorizer_post: Vectorizer  Vectorizer used to process posts\n",
    "        sliding_window: bool  Should sliding window be used or should texts be process without slicing.\n",
    "        sliding_window_pooling: str  One of 'sum', 'mul', 'mean', 'min', 'max' as defined here: https://pytorch-scatter.readthedocs.io/en/latest/functions/scatter.html\n",
    "        sliding_window_size, sliding_window_stride, sliding_window_type:  See `slice_text`\n",
    "        post_split_size: int  Batch size for post embeddings for sim calculation\n",
    "        dtype: torch.dtype  Data type in which calculate sim\n",
    "        device: str  Device on which calculate sim\n",
    "        save_if_missing: bool  Should the vectors in `dict` be saved after new vectors are calculated? This makes sense for models that will\n",
    "                be used more than once.\n",
    "    \"\"\"\n",
    "\n",
    "    print('Calculating embeddings for fact checks')\n",
    "    fact_check_embeddings = vectorizer_fact_check.vectorize(\n",
    "        dataset.id_to_fact_check.values(),\n",
    "        save_if_missing=save_if_missing,\n",
    "        normalize=True\n",
    "    )\n",
    "    fact_check_embeddings = fact_check_embeddings.transpose(0, 1)  # Rotate for matmul\n",
    "\n",
    "    fact_check_embeddings = fact_check_embeddings.to(device=device, dtype=dtype)\n",
    "\n",
    "\n",
    "    # We need to split the calculations because of memory limitations, sims matrix alone requires 200k x 25k x 4 = ~20GB RAM\n",
    "    # memory = 2**30 # assume 4gb free memory - 2**31 = 2gb for both `sims` and `sorted_ids`\n",
    "    # post_split_size = memory // len(dataset.id_to_fact_check) // 4  # // 4 because of float32\n",
    "    post_ids = iter(dataset.id_to_post.keys())\n",
    "\n",
    "    if sliding_window:\n",
    "\n",
    "        print('Splitting posts into windows.')\n",
    "        windows = [\n",
    "            slice_text(post, sliding_window_type, sliding_window_size, sliding_window_stride)\n",
    "            for post in dataset.id_to_post.values()\n",
    "        ]\n",
    "\n",
    "        print('Calculating embeddings for the windows')\n",
    "        post_embeddings = vectorizer_post.vectorize(\n",
    "            list(itertools.chain(*windows)),\n",
    "            save_if_missing=save_if_missing,\n",
    "            normalize=True\n",
    "        )\n",
    "\n",
    "        # We need to split the matrix matmul so that all the windows from each post belong to the same batch.\n",
    "        post_lengths = [len(post) for post in windows]\n",
    "        segment_array = torch.tensor([\n",
    "            i\n",
    "            for i, num_windows in enumerate(post_lengths)\n",
    "            for _ in range(num_windows)\n",
    "        ])\n",
    "        delimiters = list(gen_sliding_window_delimiters(post_lengths, post_split_size))\n",
    "\n",
    "        print('Calculating similarity for data splits')\n",
    "\n",
    "        for start_id, end_id in delimiters:\n",
    "\n",
    "            sims = torch.mm(\n",
    "                post_embeddings[start_id:end_id].to(device=device, dtype=dtype),\n",
    "                fact_check_embeddings\n",
    "            )\n",
    "\n",
    "            segments = segment_array[start_id:end_id]\n",
    "            segments -= int(segments[0])\n",
    "\n",
    "            sims = scatter(\n",
    "                src=sims,\n",
    "                index=segments,\n",
    "                dim=0,\n",
    "                reduce=sliding_window_pooling,\n",
    "            )\n",
    "\n",
    "            sorted_ids = torch.argsort(sims, descending=True, dim=1)\n",
    "\n",
    "            fact_check_ids = {i: fc_id for i, fc_id in enumerate(dataset.id_to_fact_check.keys())}\n",
    "            for row in sorted_ids:\n",
    "                row = row.cpu().numpy()\n",
    "                row = np.vectorize(fact_check_ids.__getitem__)(row)\n",
    "                yield row, next(post_ids)\n",
    "\n",
    "\n",
    "    else:\n",
    "\n",
    "        print('Calculating embeddings for posts')\n",
    "        post_embeddings = vectorizer_post.vectorize(\n",
    "            dataset.id_to_post.values(),\n",
    "            save_if_missing=save_if_missing,\n",
    "            normalize=True\n",
    "        )\n",
    "\n",
    "        print('Calculating similarity for data splits')\n",
    "        for start_id in range(0, len(dataset.id_to_post), post_split_size):\n",
    "            end_id = start_id + post_split_size\n",
    "\n",
    "            sims = torch.mm(\n",
    "                post_embeddings[start_id:end_id].to(device=device, dtype=dtype),\n",
    "                fact_check_embeddings\n",
    "            )\n",
    "\n",
    "            # TODO: argsort does not duplicities into account, the results might not be deterministic\n",
    "            # sorted_ids = torch.argsort(sims, descending=True, dim=1)\n",
    "            sorted_sims, sorted_ids = torch.sort(sims, descending=True, dim=1)\n",
    "\n",
    "            fact_check_ids = {i: fc_id for i, fc_id in enumerate(dataset.id_to_fact_check.keys())}\n",
    "            # for row in sorted_ids:\n",
    "            #     row = row.cpu().numpy()\n",
    "            #     row = np.vectorize(fact_check_ids.__getitem__)(row)\n",
    "            #     yield row, next(post_ids)\n",
    "\n",
    "            for ids_row, sims_row in zip(sorted_ids, sorted_sims):\n",
    "                ids_row = ids_row.cpu().numpy()\n",
    "                sims_row = sims_row.cpu().numpy()\n",
    "\n",
    "                fact_ids = np.vectorize(fact_check_ids.__getitem__)(ids_row)\n",
    "                yield fact_ids, sims_row, next(post_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83675772",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T03:34:02.836690Z",
     "iopub.status.busy": "2025-04-24T03:34:02.836331Z",
     "iopub.status.idle": "2025-04-24T03:34:02.849683Z",
     "shell.execute_reply": "2025-04-24T03:34:02.848714Z",
     "shell.execute_reply.started": "2025-04-24T03:34:02.836617Z"
    },
    "papermill": {
     "duration": 0.019843,
     "end_time": "2025-01-31T04:06:54.732670",
     "exception": false,
     "start_time": "2025-01-31T04:06:54.712827",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class PytorchVectorizer(Vectorizer):\n",
    "    \"\"\"\n",
    "    Vectorizer for `Pytorch` models.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        dir_path: str,\n",
    "        model_handle: str = None,\n",
    "        model: torch.nn.Module = None,\n",
    "        tokenizer = None,\n",
    "        batch_size: int = 32,\n",
    "        dtype: torch.dtype = torch.float16,\n",
    "        port_embeddings_to_cpu: bool = True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Attributes:\n",
    "            dir_path: str  Path to cached vectors and vocab files.\n",
    "            model_handle: str  Name of the model, either a HuggingFace repository handle or path to a local model.\n",
    "            model: SentenceTransformer  A loaded model -- this option can be used during fine-tuning.\n",
    "            tokenizer: AutoTokenizer  A tokenizer for the model.\n",
    "            batch_size: int  Batch size for inference\n",
    "            dtype: torch.dtype  Inference dtype\n",
    "            port_embeddings_to_cpu: bool  Whether to move the embeddings to CPU after inference.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__(dir_path)\n",
    "        \n",
    "        if model_handle:\n",
    "            self.model = torch.load(model_handle)\n",
    "            self.model.eval()        \n",
    "        else:\n",
    "            self.model = model\n",
    "\n",
    "        assert self.model\n",
    "\n",
    "        self.device = next(self.model.parameters()).device.type\n",
    "        self.tokenizer = tokenizer\n",
    "        self.batch_size = batch_size\n",
    "        self.dtype = dtype\n",
    "        self.port_embeddings_to_cpu = port_embeddings_to_cpu\n",
    "\n",
    "        \n",
    "    def _calculate_vectors(self, texts: List[str]) -> torch.tensor:\n",
    "\n",
    "        @torch.autocast(device_type=self.device.split(':')[0], dtype=self.dtype)\n",
    "        @torch.no_grad()\n",
    "        def embedding_pipeline(text: List[str], tokenizer, model, device, max_length = 512):\n",
    "            tokenized = tokenizer(text, padding=True, truncation=True, max_length=max_length, return_tensors='pt').to(device)\n",
    "            embeddings = model(**tokenized)\n",
    "            return embeddings.cpu() if self.port_embeddings_to_cpu else embeddings\n",
    "\n",
    "        return torch.vstack(\n",
    "                [\n",
    "                    embedding_pipeline(\n",
    "                        texts[i:i+self.batch_size], \n",
    "                        self.tokenizer, \n",
    "                        self.model, \n",
    "                        device=self.device, \n",
    "                    ) \n",
    "                    for i in range(0, len(texts), self.batch_size)\n",
    "                ]\n",
    "            )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60989515",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T03:34:02.850937Z",
     "iopub.status.busy": "2025-04-24T03:34:02.850567Z",
     "iopub.status.idle": "2025-04-24T03:34:02.862815Z",
     "shell.execute_reply": "2025-04-24T03:34:02.861848Z",
     "shell.execute_reply.started": "2025-04-24T03:34:02.850914Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.017412,
     "end_time": "2025-01-31T04:06:54.762224",
     "exception": false,
     "start_time": "2025-01-31T04:06:54.744812",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://github.com/mosaicml/composer/blob/dev/composer/algorithms/ema/ema.py\n",
    "Exponential Moving Average (EMA) is a model averaging technique that maintains an \n",
    "exponentially weighted moving average of the model parameters during training. \n",
    "The averaged parameters are used for model evaluation. EMA typically results \n",
    "in less noisy validation metrics over the course of training, and sometimes \n",
    "increased generalization.\n",
    "\"\"\"\n",
    "\n",
    "def compute_ema(model: torch.nn.Module, ema_model: torch.nn.Module, smoothing: float = 0.99):\n",
    "    with torch.no_grad():\n",
    "        model_params = itertools.chain(model.parameters(), model.buffers())\n",
    "        ema_model_params = itertools.chain(ema_model.parameters(), ema_model.buffers())\n",
    "\n",
    "        for ema_param, model_param in zip(ema_model_params, model_params):\n",
    "            model_param = model_param.detach()\n",
    "            ema_param.copy_(ema_param * smoothing + (1. - smoothing) * model_param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cd279b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T03:34:02.864029Z",
     "iopub.status.busy": "2025-04-24T03:34:02.863726Z",
     "iopub.status.idle": "2025-04-24T03:34:02.876266Z",
     "shell.execute_reply": "2025-04-24T03:34:02.875154Z",
     "shell.execute_reply.started": "2025-04-24T03:34:02.864001Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.02137,
     "end_time": "2025-01-31T04:06:54.795937",
     "exception": false,
     "start_time": "2025-01-31T04:06:54.774567",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://github.com/mosaicml/composer/blob/dev/composer/algorithms/sam/sam.py\n",
    "Sharpness-Aware Minimization (SAM) is an optimization algorithm that minimizes \n",
    "both the loss and the sharpness of the loss. It finds parameters that lie in \n",
    "a neighborhood of low loss. The authors find that this improves model generalization\n",
    "\"\"\"\n",
    "\n",
    "class SAM(torch.optim.Optimizer):\n",
    "    \"\"\"Wraps an optimizer with sharpness-aware minimization (`Foret et al, 2020 <https://arxiv.org/abs/2010.01412>`_).\n",
    "    See :class:`.SAM` for details.\n",
    "    Implementation based on https://github.com/davda54/sam\n",
    "    Args:\n",
    "        base_optimizer (torch.optim.Optimizer) The optimizer to apply SAM to.\n",
    "        rho (float, optional): The SAM neighborhood size. Must be greater than 0. Default: ``0.05``.\n",
    "        epsilon (float, optional): A small value added to the gradient norm for numerical stability. Default: ``1.0e-12``.\n",
    "        interval (int, optional): SAM will run once per ``interval`` steps. A value of 1 will\n",
    "            cause SAM to run every step. Steps on which SAM runs take\n",
    "            roughly twice as much time to complete. Default: ``1``.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_optimizer: torch.optim.Optimizer,\n",
    "        rho: float = 0.05,\n",
    "        epsilon: float = 1.0e-12,\n",
    "        **kwargs\n",
    "    ):\n",
    "        if rho < 0:\n",
    "            raise ValueError(f'Invalid rho, should be non-negative: {rho}')\n",
    "        self.base_optimizer = base_optimizer\n",
    "        defaults = {'rho': rho, 'epsilon': epsilon, **kwargs}\n",
    "        super(SAM, self).__init__(self.base_optimizer.param_groups, defaults)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def first_step(self):\n",
    "        grad_norm = self._grad_norm()\n",
    "        for group in self.param_groups:\n",
    "            scale = group['rho'] / (grad_norm + group['epsilon'])\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                e_w = p.grad * scale.to(p)\n",
    "                p.add_(e_w)  # climb to the local maximum \"w + e(w)\"\n",
    "                self.state[p]['e_w'] = e_w\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def second_step(self):\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None or 'e_w' not in self.state[p]:\n",
    "                    continue\n",
    "                p.sub_(self.state[p]['e_w'])  # get back to \"w\" from \"w + e(w)\"\n",
    "        self.base_optimizer.step()  # do the actual \"sharpness-aware\" update\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, step_type: str):\n",
    "        \"\"\" Adjusted to PyTorch mixed precision training framework\n",
    "        \"\"\"\n",
    "        if step_type == 'first':\n",
    "            self.first_step()\n",
    "        elif step_type == 'second':\n",
    "            self.second_step()\n",
    "        elif step_type == 'skip':\n",
    "            self.base_optimizer.step()\n",
    "\n",
    "\n",
    "    def _grad_norm(self):\n",
    "        norm = torch.norm(torch.stack(\n",
    "            [p.grad.norm(p=2) for group in self.param_groups for p in group['params'] if p.grad is not None]),\n",
    "                          p='fro')\n",
    "        return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "315b1d31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T03:34:02.877884Z",
     "iopub.status.busy": "2025-04-24T03:34:02.877537Z",
     "iopub.status.idle": "2025-04-24T03:34:02.891589Z",
     "shell.execute_reply": "2025-04-24T03:34:02.890952Z",
     "shell.execute_reply.started": "2025-04-24T03:34:02.877852Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.018314,
     "end_time": "2025-01-31T04:06:54.826588",
     "exception": false,
     "start_time": "2025-01-31T04:06:54.808274",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MNRloss(nn.Module):\n",
    "    def __init__(self, label_smoothing=0):\n",
    "        super().__init__()\n",
    "        self.loss_f = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "\n",
    "    def forward(self, sentence_embedding_A: torch.Tensor, sentence_embedding_B: torch.Tensor):\n",
    "        # Compute similarity matrix\n",
    "        scores = torch.mm(sentence_embedding_A, sentence_embedding_B.transpose(0, 1))\n",
    "        # Compute labels\n",
    "        labels = torch.arange(len(scores), dtype=torch.long, device=scores.device)\n",
    "        return self.loss_f(scores, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e531af08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T03:34:02.892791Z",
     "iopub.status.busy": "2025-04-24T03:34:02.892454Z",
     "iopub.status.idle": "2025-04-24T03:34:02.907548Z",
     "shell.execute_reply": "2025-04-24T03:34:02.906724Z",
     "shell.execute_reply.started": "2025-04-24T03:34:02.892760Z"
    },
    "papermill": {
     "duration": 0.020829,
     "end_time": "2025-01-31T04:06:54.859804",
     "exception": false,
     "start_time": "2025-01-31T04:06:54.838975",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, model_name, pooling='default', hidden_size=768, lstm_hidden_size=128):\n",
    "        super(Model, self).__init__()\n",
    "        self.pooling = pooling\n",
    "        \n",
    "        self.model = AutoModel.from_pretrained(model_name, trust_remote_code=True)\n",
    "        \n",
    "        # self.lstm = nn.LSTM(input_size=hidden_size, hidden_size=lstm_hidden_size, batch_first=True, bidirectional=True)\n",
    "        # self.attention = nn.Linear(lstm_hidden_size * 2, 1)  # Bidirectional LSTM\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids=None):\n",
    "        model_output = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_states = model_output[0]  # Shape: (batch_size, seq_len, hidden_size)\n",
    "\n",
    "        if self.pooling == 'default':\n",
    "            return model_output[1]\n",
    "        elif self.pooling == 'mean':\n",
    "            return self.mean_pooling(hidden_states, attention_mask)\n",
    "        elif self.pooling == 'attention':\n",
    "            return self.attention_pooling(hidden_states, attention_mask)\n",
    "    \n",
    "    @staticmethod\n",
    "    def mean_pooling(token_embeddings: torch.Tensor, attention_mask: torch.Tensor):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    \n",
    "    def attention_pooling(self, token_embeddings: torch.Tensor, attention_mask: torch.Tensor):\n",
    "        # Pass through LSTM\n",
    "        lstm_output, _ = self.lstm(token_embeddings)\n",
    "        \n",
    "        # Compute attention scores\n",
    "        attention_scores = self.attention(lstm_output).squeeze(-1)\n",
    "        attention_scores = attention_scores.masked_fill(attention_mask == 0, float('-inf'))\n",
    "        attention_weights = torch.softmax(attention_scores, dim=-1)\n",
    "        \n",
    "        # Compute weighted sum of token embeddings\n",
    "        attention_weights = attention_weights.unsqueeze(-1)\n",
    "        weighted_sum = torch.sum(lstm_output * attention_weights, dim=1)\n",
    "        \n",
    "        return weighted_sum\n",
    "\n",
    "def get_model_tokenizer(model_name: str, **kwargs):\n",
    "    return Model(model_name, **kwargs), AutoTokenizer.from_pretrained(model_name, use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c428127d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T03:34:02.908790Z",
     "iopub.status.busy": "2025-04-24T03:34:02.908469Z",
     "iopub.status.idle": "2025-04-24T03:34:02.923266Z",
     "shell.execute_reply": "2025-04-24T03:34:02.922567Z",
     "shell.execute_reply.started": "2025-04-24T03:34:02.908761Z"
    },
    "papermill": {
     "duration": 0.020851,
     "end_time": "2025-01-31T04:06:54.892962",
     "exception": false,
     "start_time": "2025-01-31T04:06:54.872111",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "BATCH = Tuple[Dict[str, torch.Tensor]]\n",
    "\n",
    "\n",
    "def safe_mean(x, round_to=4):\n",
    "    try:\n",
    "        return round(mean(x), round_to)\n",
    "    except StatisticsError:\n",
    "        return None\n",
    "\n",
    "def evaluate_datasets(datasets, model, tokenizer, run_path, save_vectors, batch_size):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    results = {}\n",
    "\n",
    "    vectorizer_path = run_path if save_vectors else None\n",
    "    vct = PytorchVectorizer(dir_path=vectorizer_path, model=model, tokenizer=tokenizer, \n",
    "                            batch_size=batch_size, port_embeddings_to_cpu=True)\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for dataset_name, dataset in datasets.items():\n",
    "            result_gen = embedding_results(dataset, vct, vct, post_split_size=512, device='cuda')\n",
    "            process_result_generator(result_gen, csv_path=os.path.join(run_path, dataset_name + '.csv'))\n",
    "            \n",
    "    return True\n",
    "    \n",
    "\n",
    "def predict_dataset(cfg, dev_datasets):\n",
    "    \n",
    "    try:\n",
    "        if cfg.train.output_path is not None:\n",
    "            run_path = os.path.join(cfg.train.output_path, cfg.timestamp)\n",
    "            os.makedirs(run_path)\n",
    "            # save config\n",
    "            with open(os.path.join(run_path, 'config.yaml') ,'w') as f:\n",
    "                yaml.dump(cfg.to_dict(), f, default_flow_style=False)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        model_path = os.path.join(run_path, cfg.model.name)\n",
    "        os.makedirs(model_path)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    print('Get model')\n",
    "    model, tokenizer = get_model_tokenizer(cfg.model.name, pooling=cfg.model.pooling)\n",
    "\n",
    "    # if torch.cuda.device_count() > 1:\n",
    "    #     print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "    #     model = torch.nn.DataParallel(model)\n",
    "\n",
    "    print('Loading Model Weights')\n",
    "    model.load_state_dict(torch.load(cfg.model.path, weights_only=True))\n",
    "\n",
    "    model = model.to(cfg.train.device)\n",
    "\n",
    "    print('eval done' , evaluate_datasets({**dev_datasets}, model, tokenizer, \n",
    "                                model_path, save_vectors=False, batch_size=cfg.train.batch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e8ec929",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T03:34:02.924293Z",
     "iopub.status.busy": "2025-04-24T03:34:02.924029Z",
     "iopub.status.idle": "2025-04-24T03:34:02.940303Z",
     "shell.execute_reply": "2025-04-24T03:34:02.939578Z",
     "shell.execute_reply.started": "2025-04-24T03:34:02.924272Z"
    },
    "papermill": {
     "duration": 0.023632,
     "end_time": "2025-01-31T04:06:54.928856",
     "exception": false,
     "start_time": "2025-01-31T04:06:54.905224",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fra', 'spa', 'eng', 'por', 'tha', 'deu', 'msa', 'ara')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'fra', 'spa', 'eng', 'por', 'tha', 'deu', 'msa', 'ara'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5e7d77e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T03:34:02.941494Z",
     "iopub.status.busy": "2025-04-24T03:34:02.941226Z",
     "iopub.status.idle": "2025-04-24T03:34:02.954415Z",
     "shell.execute_reply": "2025-04-24T03:34:02.953709Z",
     "shell.execute_reply.started": "2025-04-24T03:34:02.941459Z"
    },
    "papermill": {
     "duration": 0.029153,
     "end_time": "2025-01-31T04:06:54.980426",
     "exception": false,
     "start_time": "2025-01-31T04:06:54.951273",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# train_dataset = OurDataset(split='train', fold=2).load()\n",
    "\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "# train(cfg, train_dataset, dev_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3540c70",
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-24T03:38:22.511Z",
     "iopub.execute_input": "2025-04-24T03:34:06.718144Z",
     "iopub.status.busy": "2025-04-24T03:34:06.717856Z"
    },
    "papermill": {
     "duration": 3560.697076,
     "end_time": "2025-01-31T05:06:15.690882",
     "exception": false,
     "start_time": "2025-01-31T04:06:54.993806",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fact-checks.\n",
      "272447 loaded.\n",
      "Loading posts.\n",
      "8276 loaded.\n",
      "post_lang\n",
      "eng    145287\n",
      "por     32598\n",
      "spa     25440\n",
      "ara     21153\n",
      "tur     12536\n",
      "        11567\n",
      "pol      8796\n",
      "deu      7485\n",
      "fra      6316\n",
      "msa       686\n",
      "tha       583\n",
      "Name: count, dtype: int64\n",
      "task lang fact checks 272447\n",
      "task lang post dev 4000\n",
      "Filtering by split: 4000 posts remaining and sampled 272447 fact checks\n",
      "Filtering fact-checks by language: 272447 posts remaining.\n",
      "Filtering posts by language: 4000 posts remaining.\n",
      "Filtering posts.\n",
      "Posts remaining: 4000\n",
      "Get model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6311a4cbf433487baed3f45c01b46860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/690 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6f2cdd96cf4a3f89311b68665c734f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bd34014aff64782ad7eaabd22a2616a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c06ce645da4d49e28dc63ba275b0bbfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a46b24cb3964afd85efbc3bc999f3d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ce1ff1627d4875b61576ac7b3351a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model Weights\n",
      "Calculating embeddings for fact checks\n",
      "Calculating 272256 vectors.\n"
     ]
    }
   ],
   "source": [
    "cfg = Config()\n",
    "cfg.model.name = 'intfloat/multilingual-e5-large-instruct'\n",
    "cfg.model.path = 'model-weights/multilingual-e5-large-instruct_f0_mean.pt'\n",
    "cfg.model.pooling = 'mean'\n",
    "cfg.train.batch_size = 512\n",
    "cfg.train.p_max_seq_length: int = 768\n",
    "cfg.train.fc_max_seq_length: int = 768\n",
    "dev_dataset = {'dev_cross': OurDataset(split='test', language = 'cross').load()}\n",
    "predict_dataset(cfg, dev_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11045a8d",
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-24T03:38:22.511Z"
    },
    "papermill": {
     "duration": 3522.867809,
     "end_time": "2025-01-31T06:04:58.579661",
     "exception": false,
     "start_time": "2025-01-31T05:06:15.711852",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cfg = Config()\n",
    "cfg.model.name = 'intfloat/multilingual-e5-large-instruct'\n",
    "cfg.model.path = 'model-weights/multilingual-e5-large-instruct_f1_mean.pt'\n",
    "cfg.model.pooling = 'mean'\n",
    "cfg.train.batch_size = 512\n",
    "cfg.train.p_max_seq_length: int = 768\n",
    "cfg.train.fc_max_seq_length: int = 768\n",
    "dev_dataset = {'dev_cross': OurDataset(split='test', language = 'cross').load()}\n",
    "predict_dataset(cfg, dev_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bec9f3b",
   "metadata": {
    "papermill": {
     "duration": 0.014341,
     "end_time": "2025-01-31T06:04:58.609562",
     "exception": false,
     "start_time": "2025-01-31T06:04:58.595221",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6467824,
     "sourceId": 10462843,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6185840,
     "sourceId": 10910871,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7109.775986,
   "end_time": "2025-01-31T06:05:02.580700",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-31T04:06:32.804714",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "011380c528754c4087cf64116fb82636": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "022966db527b4719affb7d925619912d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_299ba9a6d04a405a8c7c337a59f3d6cb",
        "IPY_MODEL_3ddaead31c2f42a2945ba003b48a7f33",
        "IPY_MODEL_9825be5394ce436c94e926beb5211d27"
       ],
       "layout": "IPY_MODEL_fa3292aa900f4858ad2029b354e9b16a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "046cb5b67f51447082469400d2911504": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0626e7dbbf3542c0ab39e70037efe01d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0c300f8464c54426b859b9c016ae93a4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "10ced53be484406a81b43782eb09b74e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "17a08f37101f4d76af0ba5866e4e8ca5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0626e7dbbf3542c0ab39e70037efe01d",
       "max": 690,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_282968809b6c4169bef73eea7f880b84",
       "tabbable": null,
       "tooltip": null,
       "value": 690
      }
     },
     "1a9476b189994e1192ed285b4d19c15f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4103122c29b445c6bba2480925d61399",
        "IPY_MODEL_50072858b9db42f581d97c95fc42d462",
        "IPY_MODEL_45b1ff54087c4a138938a5c2c9ace850"
       ],
       "layout": "IPY_MODEL_9f2cbd730b294406a22cefd7a70a7d14",
       "tabbable": null,
       "tooltip": null
      }
     },
     "2114ed7729594a6686664fc8ad652a1c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_594fd135b7414e23b3d689d7d2ab1bb7",
       "placeholder": "​",
       "style": "IPY_MODEL_d4f298a4d818459cb621760177b12a69",
       "tabbable": null,
       "tooltip": null,
       "value": " 690/690 [00:00&lt;00:00, 68.7kB/s]"
      }
     },
     "282968809b6c4169bef73eea7f880b84": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "299ba9a6d04a405a8c7c337a59f3d6cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_fc65009b0e624a15b8ec3dcdb93e869b",
       "placeholder": "​",
       "style": "IPY_MODEL_9f99d7ea45b94be2939f39771a1c2ef1",
       "tabbable": null,
       "tooltip": null,
       "value": "sentencepiece.bpe.model: 100%"
      }
     },
     "3647a7f03710443db5d7ceba48c3ac35": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3bf1556365d14768b2d980a04413ba09": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3ddaead31c2f42a2945ba003b48a7f33": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_45cb2032b35e4c808912a1e41398563a",
       "max": 5069051,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7eead2e154a549dba90fefbb29c5adc7",
       "tabbable": null,
       "tooltip": null,
       "value": 5069051
      }
     },
     "3f8ea9bd24fe4ab6a6aefbb0636bbe6d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0c300f8464c54426b859b9c016ae93a4",
       "placeholder": "​",
       "style": "IPY_MODEL_82e4c8c1f8b6427d9276b37b6210325c",
       "tabbable": null,
       "tooltip": null,
       "value": " 17.1M/17.1M [00:00&lt;00:00, 42.8MB/s]"
      }
     },
     "4103122c29b445c6bba2480925d61399": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_dfaeb9158e1b46bcbe5778aa380a55fb",
       "placeholder": "​",
       "style": "IPY_MODEL_51a5405b602d48bc802b55ca8b4679c0",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "45b1ff54087c4a138938a5c2c9ace850": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e7bb8df6bcde44d984b7ba7a5b7e76d2",
       "placeholder": "​",
       "style": "IPY_MODEL_df1d2defd5944f9ba197b92c38ce687e",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.12G/1.12G [00:26&lt;00:00, 43.3MB/s]"
      }
     },
     "45cb2032b35e4c808912a1e41398563a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "45ff59e94db940c394ee5d5260b0d537": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "46be2f0036b34bb3996e5eb3b91fc3ff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4975cdf33e6a46bfb1ed26520248bff1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "50072858b9db42f581d97c95fc42d462": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ff4590bb17c94c9091957f16a9a2c1f0",
       "max": 1119825680,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_816c2d241bf14c469f2a9ea4c359dd48",
       "tabbable": null,
       "tooltip": null,
       "value": 1119825680
      }
     },
     "51a5405b602d48bc802b55ca8b4679c0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "51fa51e130f44c0ab6296d8ed0ccece8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "594fd135b7414e23b3d689d7d2ab1bb7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6732e47d0c81426d8da3ac06231bd1ff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "684bbe6b9e684e72aeb612bd91a424c6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "70fef97b4d5e4271819823fdb7ea9a44": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f533de5a80d3481db783b7c619f5ba97",
       "placeholder": "​",
       "style": "IPY_MODEL_af4299eb5ee0423898da193aaf809624",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.18k/1.18k [00:00&lt;00:00, 124kB/s]"
      }
     },
     "71913ad29fcf4dde9290c59f23686b9b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "74bed6708e18419ea063e4965752ec3f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_45ff59e94db940c394ee5d5260b0d537",
       "placeholder": "​",
       "style": "IPY_MODEL_e05cc0123bbc454b861b4ca8b533d29f",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer.json: 100%"
      }
     },
     "7eead2e154a549dba90fefbb29c5adc7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "816c2d241bf14c469f2a9ea4c359dd48": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "82e4c8c1f8b6427d9276b37b6210325c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "832e6b29a85049a7ac05720c65202750": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8476056da9ab4374bbf3d45c36efb7a6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9825be5394ce436c94e926beb5211d27": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a217c4fa85084b2e9691d18ccb440250",
       "placeholder": "​",
       "style": "IPY_MODEL_51fa51e130f44c0ab6296d8ed0ccece8",
       "tabbable": null,
       "tooltip": null,
       "value": " 5.07M/5.07M [00:00&lt;00:00, 41.6MB/s]"
      }
     },
     "99a24440147b41cb87aab039f7a84cb4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9f0c7fc943354d6da60c2facf37f8888": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f36ff0f808c1432288bab62171c48fe6",
       "placeholder": "​",
       "style": "IPY_MODEL_684bbe6b9e684e72aeb612bd91a424c6",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "9f2cbd730b294406a22cefd7a70a7d14": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9f99d7ea45b94be2939f39771a1c2ef1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a1bb99244cfd478189c5f5ac9bf43348": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_10ced53be484406a81b43782eb09b74e",
       "placeholder": "​",
       "style": "IPY_MODEL_99a24440147b41cb87aab039f7a84cb4",
       "tabbable": null,
       "tooltip": null,
       "value": " 964/964 [00:00&lt;00:00, 96.3kB/s]"
      }
     },
     "a217c4fa85084b2e9691d18ccb440250": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "af4299eb5ee0423898da193aaf809624": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b2134e0f0239437094d15fcfc7deb9f6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b95df7fed9a74a21b3004acf179ee7e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_fdf844a1c67e46a3884b4fd3ad1f22bb",
       "placeholder": "​",
       "style": "IPY_MODEL_3bf1556365d14768b2d980a04413ba09",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json: 100%"
      }
     },
     "bf693c41f4c74a7badfb4920d7ed5ab2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c420c045c3e243a3a9320f0f01f21617": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c86c88d3374848b88537f001b446d2d8",
        "IPY_MODEL_17a08f37101f4d76af0ba5866e4e8ca5",
        "IPY_MODEL_2114ed7729594a6686664fc8ad652a1c"
       ],
       "layout": "IPY_MODEL_011380c528754c4087cf64116fb82636",
       "tabbable": null,
       "tooltip": null
      }
     },
     "c86c88d3374848b88537f001b446d2d8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_46be2f0036b34bb3996e5eb3b91fc3ff",
       "placeholder": "​",
       "style": "IPY_MODEL_bf693c41f4c74a7badfb4920d7ed5ab2",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "d4f298a4d818459cb621760177b12a69": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d8eec57eb969423688f6a16cc7851918": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "df1d2defd5944f9ba197b92c38ce687e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "dfaeb9158e1b46bcbe5778aa380a55fb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e05cc0123bbc454b861b4ca8b533d29f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e64b1dd7c4924b22be748c68f2f768f5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b95df7fed9a74a21b3004acf179ee7e8",
        "IPY_MODEL_eb7595e8a9e140bc978ca1ca9357a0c5",
        "IPY_MODEL_a1bb99244cfd478189c5f5ac9bf43348"
       ],
       "layout": "IPY_MODEL_b2134e0f0239437094d15fcfc7deb9f6",
       "tabbable": null,
       "tooltip": null
      }
     },
     "e6e5c4a701fb460eaba9e7aebb006591": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9f0c7fc943354d6da60c2facf37f8888",
        "IPY_MODEL_f016925d0a304b8d91bc37a1fc96243c",
        "IPY_MODEL_70fef97b4d5e4271819823fdb7ea9a44"
       ],
       "layout": "IPY_MODEL_832e6b29a85049a7ac05720c65202750",
       "tabbable": null,
       "tooltip": null
      }
     },
     "e7bb8df6bcde44d984b7ba7a5b7e76d2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eb7595e8a9e140bc978ca1ca9357a0c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_046cb5b67f51447082469400d2911504",
       "max": 964,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3647a7f03710443db5d7ceba48c3ac35",
       "tabbable": null,
       "tooltip": null,
       "value": 964
      }
     },
     "f016925d0a304b8d91bc37a1fc96243c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_71913ad29fcf4dde9290c59f23686b9b",
       "max": 1182,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d8eec57eb969423688f6a16cc7851918",
       "tabbable": null,
       "tooltip": null,
       "value": 1182
      }
     },
     "f36ff0f808c1432288bab62171c48fe6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f4e68165449442d6af8cc9ad0b079221": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_74bed6708e18419ea063e4965752ec3f",
        "IPY_MODEL_fe8fb309205a412eafd59779ae999f54",
        "IPY_MODEL_3f8ea9bd24fe4ab6a6aefbb0636bbe6d"
       ],
       "layout": "IPY_MODEL_6732e47d0c81426d8da3ac06231bd1ff",
       "tabbable": null,
       "tooltip": null
      }
     },
     "f533de5a80d3481db783b7c619f5ba97": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fa3292aa900f4858ad2029b354e9b16a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fc65009b0e624a15b8ec3dcdb93e869b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fdf844a1c67e46a3884b4fd3ad1f22bb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fe8fb309205a412eafd59779ae999f54": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8476056da9ab4374bbf3d45c36efb7a6",
       "max": 17082756,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4975cdf33e6a46bfb1ed26520248bff1",
       "tabbable": null,
       "tooltip": null,
       "value": 17082756
      }
     },
     "ff4590bb17c94c9091957f16a9a2c1f0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
